{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εξόρυξη Δεδομένων\n",
    "### Εργασία Χειμερινού Εξαμήνου \n",
    "### Ακαδημαικό Έτος 2019-2020\n",
    "#### Στρίκλαντ Ελένη 3140252\n",
    "#### Μπούσουλας-Ραϊκίδης Ορφέας-Γεώργιος 3160111\n",
    "Όνομα ομάδας στο Kaggle: InfinityLoops w/o Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εισαγωγή \n",
    "\n",
    "Στο πλάισιο του μαθήματος Εξόρυξη Δεδομένων απο Βάσεις Δεδομένων και τον Παγκόσμιο Ιστό μας ανατέθηκε να λύσουμε ένα πρόβλημα παλινδρόμησης. Συγκεκριμένα, μας δόθηκε ένα σύνολο δεδομένων που αποτελείται από μερικές χιλιάδες εγγραφές που περιέχουν την ωριαία μέτρηση των ενοικιαζόμενων ποδηλάτων μεταξύ των ετών 2011 και 2012 στο σύστημα Capital bikeshare με τις αντίστοιχες καιρικές και εποχιακές πληροφορίες.\n",
    "\n",
    "Ο στόχος μας είναι να προβλέψουμε πόσα ποδήλατα θα ενοικιάζονται κάθε ώρα της ημέρας, με βάση δεδομένα όπως ο καιρός, ο χρόνος, η θερμοκρασία, αν η ημέρα είναι εργασιμή ή οχι, ή έαν είναι περιοδος διακοπών ή εορτών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import stats\n",
    "from numpy import median\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSLE score calculation\n",
    "def rmsle_score(y_true, y_pred):\n",
    "    for i, y in enumerate(y_pred):\n",
    "        if y_pred[i] < 0:\n",
    "            y_pred[i] = 0\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Datasets\n",
    "filename = 'dataset/train.csv' \n",
    "df_train = pd.read_csv(filename)\n",
    "\n",
    "df_train.shape\n",
    "df_test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "df_test.shape\n",
    "df_train.isnull().sum()\n",
    "df_train.rename(columns={'weathersit':'weather',\n",
    "                     'mnth':'month',\n",
    "                     'hr':'hour',\n",
    "                     'yr':'year',\n",
    "                     'hum': 'humidity',\n",
    "                     'cnt':'count'},inplace=True)\n",
    "\n",
    "#Not used in final submission\n",
    "# df_train.dtypes\n",
    "# df_train['season'] = df_train.season.astype('category')\n",
    "# df_train['year'] = df_train.year.astype('category')\n",
    "# df_train['month'] = df_train.month.astype('category')\n",
    "# df_train['weekday'] = df_train.weekday.astype('category')\n",
    "# df_train['hour'] = df_train.hour.astype('category')\n",
    "# df_train['holiday'] = df_train.holiday.astype('category')\n",
    "# df_train['workingday'] = df_train.workingday.astype('category')\n",
    "# df_train['weather'] = df_train.weather.astype('category')\n",
    "# df_train.dtypes\n",
    "\n",
    "#Setting training data\n",
    "df_train = df_train.drop(['windspeed','atemp', 'casual', 'registered'], axis=1)\n",
    "X = df_train[['temp', 'humidity', 'hour', 'month','workingday', 'holiday', 'season','weekday', 'year', 'weather']]\n",
    "y = df_train['count']\n",
    "# Training and test data is created by splitting the main data. 20% of test data is considered\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ενότητα 1: Ανάλυση Δεδομένων\n",
    "\n",
    "Πριν ξεκινήσουμε να δοκιμάζουμε αλγορίθμους machine learning προσπαθήσαμε να δουλέψουμε λίγο με τα δεδομένα που μας δόθηκαν. Παρατηρήσαμε ότι πολλά απο τα attributes είναι κατηγορικές μεταβλητές και δουλέψαμε λίγο με τον κώδικα που μας δόθηκε απο την εκφώνηση ο οποίος σε πρώτο στάδιο χρησιμοποιεί τον Linear Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Μέγεθος Test dataset\n",
    "\n",
    "Δοκιμάσαμε αρχικά να αλλάξουμε το μέγεθος του test dataset και αντί για 30% να παίρνει περισσότερα δεδομένα από το train dataset, πράγμα που οδήγησε σε μία ελαφρά μείωση του σκορ διατηρώντας ίδια χαρακτηριστικά.  Ωστόσο, αποφασίσουμε να κρατήσουμε το 20%, έτσι ώστε να βελτιώσουμε πρώτα τον αλγόριθμο χωρίς να αυξηθεί ο χρόνος εκτέλεσης του."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Χρονική Ανάλυση\n",
    "Η αμέσως επόμενη προσσέγγιση του προβλήματος ήταν η χρονική ανάλυση. Για το σκοπό αυτό δημιουργήσαμε το χαρακτηριστικό Date που αποτελεί μία συννένωση του year και month. Με τη βοήθεια της pandas μετατρέψαμε το year από την μορφή 0-1 σε 2011-2012 (που είναι τα έτη των μετρήσεων) και παράξαμε στοιχεία της μορφής year-month (π.χ. 2011-01) ως datetime64. Έπειτα δημιουργήσαμε ένα διάγραμμα για να δούμε την εξέλιξη του count σε συνάρτηση με τη ροή του χρόνου (2011-01  έως 2012-12). \n",
    "\n",
    "![Εικόνα διαγράμματος χρόνου](img/timeFlowWanted.png)\n",
    "\n",
    "Αυτό που παρατηρήσαμε από το συγκεκριμένο διάγραμμα είναι πως το 2012 νοικιάστηκαν περισσότερα ποδήλατα από ότι το 2011 στους ίδιους μήνες, ενώ σημαντικό ρόλο διαδραματίζει η εποχή καθώς τους καλοκαιρινούς μήνες νοικιάζονται πολλά παραπάνω ποδήλατα από ότι τους χειμερινούς. Ωστόσο, δεν χρησιμοποιήσαμε αυτή την προσσέγγιση τελικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['year']=df_train['year'].apply(lambda x: '2011' if x == '0' else '2012')\n",
    "# df_train['date']=df_train[['year','month']].apply(lambda x: '-'.join(x), axis = 1)\n",
    "# df_train['date']=pd.to_datetime(df_train['date'], errors='ignore')\n",
    "# df_train=df_train.sort_values(by=['date', 'hour'])\n",
    "# print(df_train)\n",
    "# df_train['date'] = df_train.date.astype('datetime64').astype(int).astype(float)\n",
    "\n",
    "# fig,[ax1,ax2] = plt.subplots(nrows=2, figsize=(20,10))\n",
    "# sn_plot =sn.lineplot(x=\"date\", y=\"count\", data=df_train, palette=\"tab10\", linewidth=2.5,ax = ax1)\n",
    "# sn_plot.figure.savefig(\"timeFlow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Φιλτράρισμα τιμών\n",
    "Άλλη μία ιδέα που υλοποιήσαμε για να έχουμε καλύτερα αποτελέσματα είναι να χρησιμοποιήσουμε Outliers. Ουσιαστικά φτιάξαμε ένα διάγραμμα το οποίο έδειχνε για όλες τις εγγραφές πόσα ποδήλατα ενοικιάστηκαν. Παρατηρήσαμε ότι ο μέσος όρος κυμένεται απο το 300 έως το 500 οπότε αποφασίσαμε να αφαιρέσουμε απο το dataset όλες τις εγγραφές με count μεγαλύτερο του 500. Παρακάτω φαίνεται το αντίστοιχο διαγραμμα. \n",
    "\n",
    "![](img/outliers.png)\n",
    "\n",
    "Αν και στον αλγόριμο Linear Regression η αφαίρεση των outliers έδινε καλύτερα αποτελέσματα, στους υπόλοιπους αλγορίθμους που βασίζονται κυρίως σε δέντρα τα αποτελέσματα ήταν λιγότερα, οπότε δεν χρησιμοποιήσαμε αυτή τη μέθοδο τελικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.drop(df_train[df_train['count'] > 500].index)\n",
    "# df_train= df_train.sort_values(by='count')\n",
    "# outliers_dataset=df_train['count'].copy()\n",
    "# sn.relplot(data=outliers_dataset, ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ενότητα 2. Regressors\n",
    "\n",
    "Να σημειωθεί ότι για την εύρεση καλύτερων αποτελεσμάτων χρησιμοποιούμε Grid Search CV σε όλους τους αλγορίθμους που θα εφαρμόσουμε στην συνέχεια, για την καλύτερη παραμετροποίηση τους. \n",
    "\n",
    "### Ενότητα 2.1: Linear Regression\n",
    "\n",
    "Για την αρχική προσέγγιση του προβλήματος επικεντρωθήκαμε στο να αξιοποιήσουμε τον κώδικα που μας δόθηκε ως παράδειγμα από το εργαστήριο. Χρησιμοποιώντας, λοιπόν, τον αλγόριθμο Linear Regression και εκτελώντας τον κώδικα της εργασίας το score που υπολογίστηκε με την μέθοδο RMSLE (Root Mean Squared Logarithmic Error) και τα χαρακτιριστικά temp, humidity, workingday έδωσε 1.4089. \n",
    "\n",
    "##### Διαλέγοντας Χαρακτηριστικά\n",
    "Επιλέγοντας διαφορετικά χαρακτηριστικά προσπαθήσαμε να δούμε πως κινείται το σκορ  και στον παρακάτω πίνακα φαίνονται τα αποτελέσματα για μερικούς συνδυασμούς με το αντίστοιχο score στα training data.\n",
    "\n",
    "|χαρακτιριστικά|σκορ|\n",
    "|----------------|--------|\n",
    "|temp, year, month, weekday, hour, weather|**1.3129**|\n",
    "|temp, month, hour, weather, season|**1.2795**|\n",
    "|temp, month, hour, weather|**1.2867**|\n",
    "|temp, hour, weather,season,weekday|**1.2829**|\n",
    "|temp, hour, humidity|**1.2523**| \n",
    "\n",
    "Ακόμα, δοκιμάσαμε να χρησιμοποιήσουμε όλα τα χαρακτηριστικά (και τα 12), αλλά το σκορ ανέβαινε με κάθε επιπλέον χαρακτιριστικό που προσθέταμε.Οπότε αποφασίσαμε να χρησιμοποιήσουμε όσο το δυνατόν λιγότερα χαρακτηριστικά, για αυτό επιλέξαμε αυτά που μείωναν το σκορ περισσότερο στις δοκιμές που κάναμε στο τοπικό σετ δεδομένων. Έτσι καταλήξαμε σε:\n",
    "\n",
    "```temp, humidity, hour με σκορ 1.2523```\n",
    "\n",
    "Ωστόσο υποβάλλοντας τα αποτελέσματα στο Kaggle.com λάβαμε σκορ 1.64, οπότε καταλάβαμε πως αυτή η προσσέγγιση του προβλήματος δεν μας δίνει καλή γενίκευση, αν και δουλέυει καλά για το μικρό σετ δεδομένων που έχουμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression(n_jobs = -1)\n",
    "# parameters = {'normalize': [False]}\n",
    "# lr_cv = GridSearchCV(lr, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# lr_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_lr = lr_cv.predict(X_test)\n",
    "\n",
    "# print('Random Forest Best Parameters:', lr_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.2: Support Vector Machine\n",
    "\n",
    "Ενώ η μέθοδος SVR είναι πολύ δημοφιλής για την λύση προβλημάτων παλινδρόμησης δεν μας βοήθησε ιδιαίτερα. Τα αποτελέσματα ήταν παρόμοια με την Linear Regression, ενώ εδινε λίγο καλύτερο score στα training data, 1,15 για την ακρίβεια, στο συνολικό dataset το score ανέβηκε στο 1,75. Η μέθοδος θα λέγαμε δεν είναι και πολύ κατάλληλη εφόσον ψάχνουμε μία εκτίμηση ως προς την μεταβλητή count, δηλαδή τον αριθμό των ποδηλάτων των οποίων ενοικιάστηκαν.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmr = LinearSVR(random_state=0)\n",
    "# parameters = {'tol': [1e-03], 'max_iter': [10]}\n",
    "# svmr_cv = GridSearchCV(svmr, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# svmr_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_svmr = svmr_cv.predict(X_test)\n",
    "\n",
    "# print('SVM Parameters:', svmr_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_svmr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.3: Random Forest Regressor\n",
    "\n",
    "Επειδή το dataset περιέχει πολλές κατηγορικές μεταβλητές αποφασίσαμε να να χρησιμοποιήσουμε των αλγόριθμο Random Forest Regressor, δεδομένου ότι οι αλγόριθμοι που χρησιμοποιούν δέντρα απόφασης είναι πολύ πιο αποδοτικά στο ζήτημα των κατηγορικών μεταβλητών. Τα αποτελέσματα στον σκορ ήταν ιδιαίτερα θετικά , αφου καταφέραμε να το ρίξουμε στο 0,33, οπότε αυτός θα είναι και ο βασικός αλγοριθμος που θα χρησιμοποιήσουμε. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestRegressor(n_jobs = 4, random_state = 0, verbose = 1)\n",
    "# parameters = {'n_estimators': [1000], 'max_depth': [25]}\n",
    "# clf_cv = GridSearchCV(clf, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# clf_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf_cv.predict(X_test)\n",
    "\n",
    "# print('Random Forest Best Parameters:', clf_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.4: Κ-Nearest Neighbors \n",
    "\n",
    "Επόμενος αλγόριθμος που επιλέξαμε να δοκιμάσουμε για τη λύση του προβλήματος παλινδρόμησης έιναι ο Knn. Ο Knn μας έδωσε score 0,39. Πολύ καλό αποτέλεσμα αλλα όχι κάτι καλύτερο απο τον Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kn = KNeighborsRegressor(n_jobs = 4)\n",
    "# parameters = {'n_neighbors': [7],  'weights': ['distance'], 'p': [1]}\n",
    "# kn_cv = GridSearchCV(kn, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# kn_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_kn = kn_cv.predict(X_test)\n",
    "\n",
    "# print('KNeighbors Parameters:', kn_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_kn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.5: Gradient Boosting Regressor\n",
    "\n",
    "Ο Gradient Boosting Regressor είναι ένας καλός αλγόριθμος για την λύση του προβλήματος μας. Αν και είχε καλή απόδοση ήταν πάρα πολύ αργός (λόγο του ότι δεν τρέχει σε παραλληλία) γι αυτό και ορίσαμε 100 estimators με σκοπό να μειώσουμε την χρονική διάρκεια του. Τo score του στα training data είναι 0.37."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GradientBoostingRegressor(random_state = 42, verbose= 1)\n",
    "# parameters = {'n_estimators': [100],  'criterion': ['mae'], 'max_depth': [15]}\n",
    "# gb_cv = GridSearchCV(gb, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# gb_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_gb = gb_cv.predict(X_test)\n",
    "\n",
    "# print('GradientBoosting Parameters:', gb_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_gb)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.6: Extra Trees Regressor\n",
    "\n",
    "Εφόσον ο Random Forest Regressor μας έριξε πάρα πολύ το score αποφασίσαμε να δοκίμασου παρόμοιο αλγόριθμο με decision trees, ο οποίος έδωσε το ίδιο score με τον Random Forest, 0,33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext = ExtraTreesRegressor(random_state = 42, n_jobs= 4, verbose= 1)\n",
    "# parameters = {'n_estimators': [100],  'criterion': ['mse'], 'max_depth': [25]}\n",
    "# ext_cv = GridSearchCV(ext, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# ext_cv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_ext = ext_cv.predict(X_test)\n",
    "\n",
    "# print('ExtraTree Parameters:', ext_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_ext)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.7: Bagging Regressor\n",
    "\n",
    "Το ίδιο score έδωσε και ο Bagging Regressor, 0,33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag = BaggingRegressor(random_state = 42, verbose= 1)\n",
    "# parameters = {'n_estimators': [5,10,50,100,1000]}\n",
    "# bag_cv = GridSearchCV(bag, parameters, cv=5, n_jobs=-1, verbose = 1)\n",
    "# bag_cv.fit(X_train, y_train)\n",
    "# y_pred_bag = bag_cv.predict(X_test)\n",
    "\n",
    "# print('Bagging Parameters:', bag_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_bag)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ενότητα 2.8: Hist Gradient Boosting Regressor\n",
    "\n",
    "Ακόμα δοκιμάσαμε και έναν πειραματικό αλγόριθμο του sklearn, τον Hist Gradient Boosting Regressor. To score ήταν ικανοποιητικό στο 0.46 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingRegressor Parameters: {'learning_rate': 0.1, 'max_depth': 20, 'max_iter': 1000}\n",
      "RMSLE: 0.4618802059113205\n"
     ]
    }
   ],
   "source": [
    "# hgb = HistGradientBoostingRegressor(random_state = 42)\n",
    "# parameters = {'max_iter': [1000], 'max_depth':[20], 'learning_rate':[0.1]}\n",
    "# hgb_cv = GridSearchCV(hgb, parameters, cv=5, n_jobs=-1)\n",
    "# hgb_cv.fit(X_train, y_train)\n",
    "# y_pred_hgb = hgb_cv.predict(X_test)\n",
    "\n",
    "# print('HistGradientBoostingRegressor Parameters:', hgb_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_hgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Σημείωση: Δοκιμάσαμε και πολλούς άλλους αλγορίθμους, αλλά οι προσεγγίσεις ή τα αποτελέσματα τους δεν μας ικανοποίησαν και τόσο, οπότε δεν τους αναφέρουμε εδώ. Μερικά παραδείγματα Adaboost, DecisionTreeRegressor, KDTree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ενότητα 3: XGBoost \n",
    "Εκτός από τους αλγορίθμους του sklearn υλοποιήσαμε και μία εκδοχή του αλγορίθμου XGBRegressor από το πακέτο XGBoost. Από τα αποτελέσματα φάνηκε πως είναι ένας πολύ καλός αλγόριθμος που μας έδωσε score 0.2866. Οπότε αποφασίσαμε πως είναι ένας από τους βασικούς που θέλουμε να χρησιμοποιήσουμε.\n",
    "Ωστόσο, για να μας δώσει αυτό το score κάναμε κάποιες αλλαγές στα δεδομένα μας. Συγμεκριμένα, δεν μετατρέψαμε κανένα από τα attributes σε κατηγορικό. Επίσης, κατά το fitting του μοντέλου χρησιμοποιούμε μία λογαριθμική συνάρτηση για το y_train. Στην συνέχεια επαναφέρουμε τα δεδομένα που προκύπτουν από το prediction του xgboost στην αρχική τους κατάσταση με μία εκθετική συνάρτηση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg = XGBRegressor(subsample = 0.5, max_depth= 9, nthread = -1, silent = 1)\n",
    "\n",
    "# xg.fit(X_train, np.log(y_train))\n",
    "# y_pred = np.exp(xg.predict(X_test))\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ενότητα 4: Νευρωνικά Δίκτυα - SciKit Learn\n",
    "Γενικά είπαμε να μην χρησιμοποιήσουμε νευρωνικά δίκτυα, κυρίως γιατί θέλαμε να πειραματιστούμε με μία λύση που θα ακολουθούσε μια διαφορετική προσσέγγιση. Όμως, κάναμε μία υλοποίηση του MLPRegressor που παρέχει το sklearn. Πειραματιζόμενοι με αυτή την μέθοδο καταφέραμε ένα score της τάξεως του 0.34. Βρήκαμε το συγκεκριμένο μοντέλο αργό και για αυτό δεν συνεχίσαμε παραπάνω, ενώ δεν καταφέραμε να το παραμετροποιήσουμε ώστε να μας δώσει καλύτερα αποτελέσματα από το μοντέλο του xgboost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_cv = MLPRegressor(hidden_layer_sizes = (256,128,64,32,16), activation = 'relu', solver = 'adam', max_iter = 1000,learning_rate_init = 0.001, epsilon = 1e-8, random_state = 42, verbose = 1)\n",
    "# parameters = {'epsilon':[1e-7] }\n",
    "# nn_cv = GridSearchCV(nn_cv, parameters, cv=5, n_jobs=-1)\n",
    "# nn_cv.fit(X_train, y_train)\n",
    "# y_pred_nn = nn_cv.predict(X_test)\n",
    "\n",
    "# print('MLPRegressor Parameters:', nn_cv.best_params_)\n",
    "# print('RMSLE:', rmsle_score(y_test, y_pred_nn)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ενότητα 5: Συνδυασμός Μεθόδων (Voting) Τελική Υποβολή\n",
    "\n",
    "Για την τελική μας λύση στο πρόβλημα, στραφήκαμε προς το μοντέλο του Voting. Δηλαδή των συνδυασμό πολλών αλγορίθμων που γίνονται fit μέσω του VotingRegressor του sklearn.\n",
    "\n",
    "Οι αλγόριθμοι που επιλέξαμε είναι ο RandomForestRegressor, KNeighborsRegressor, ExtraTreesRegressor, BaggingRegressor, HistGradientBoostingRegressor και φυσικά ο XGBRegressor. Όπως και στον xgboost, λογαριθμούμε κατά το fitting και μετά επαναφέρουμε κατά το prediction τα δεδομένα μας. Το score στα training data είναι 0.28151 νώ η πλατφόρμα Kaggle έβγαλε 0.28634, το καλύτερο score μεχρι στιγμής. Για την υλοποίηση του Voting δίνουμε περισσότερο βάρος σε κάποιους αλγορίθμους:\n",
    "\n",
    "|Αλγόριθμος|Βάρος|\n",
    "|----------------|--------|\n",
    "|RandomForestRegressor|1|\n",
    "|KNeighborsRegressor|1|\n",
    "|BaggingRegressor|1|\n",
    "|HistGradientBoostingRegressor|1|\n",
    "|ExtraTreesRegressor|2\n",
    "|XGBRegressor|5\n",
    "\n",
    "Η συγκεκριμένη μέθοδος βοηθά στο να βελτιώσουμε το αποτέλεσμα που προκύπτει από δεδομένα που δυσκολέυουν έναν αλγόριθμό, αλλά είναι πιο εύκολα διαχειρίσιμα από κάποιον άλλο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting RMSLE score: 0.2815137572214321\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=1000, max_depth=25, n_jobs = -1, random_state = 0)\n",
    "kn = KNeighborsRegressor(n_neighbors=7,  weights='distance', p=1, n_jobs = -1)\n",
    "ext = ExtraTreesRegressor(n_estimators=100,criterion='mse',max_depth=25, random_state = 42, n_jobs= -1)\n",
    "bag = BaggingRegressor(n_estimators = 1000, random_state = 42)\n",
    "hgb = HistGradientBoostingRegressor(max_iter = 1000, max_depth = 20, learning_rate = 0.1, random_state = 42)\n",
    "xg = XGBRegressor(subsample = 0.5, max_depth= 9, nthread = -1, silent = 1)\n",
    "\n",
    "voting = VotingRegressor(estimators=[('kn', kn), ('clf', clf), ('ext',ext), ('bag',bag), ('hgb', hgb),('xg',xg)], weights=[1,1,2,1,1,5], n_jobs=-1)\n",
    "voting.fit(X_train,np.log(y_train))\n",
    "y_pred_voting = np.exp(voting.predict(X_test))\n",
    "print('Voting RMSLE score:', rmsle_score(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission \n",
    "Τέλος, παράγουμε το αρχείο υποβολής για το Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dataset/test.csv' \n",
    "df_test = pd.read_csv(filename)\n",
    "\n",
    "df_test.shape\n",
    "df_test.rename(columns={'weathersit':'weather',\n",
    "                     'mnth':'month',\n",
    "                     'hr':'hour',\n",
    "                     'yr':'year',\n",
    "                     'hum': 'humidity',\n",
    "                     'cnt':'count'},inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# df_test['season'] = df_test.season.astype('category')\n",
    "# df_test['year'] = df_test.year.astype('category')\n",
    "# df_test['month'] = df_test.month.astype('category')\n",
    "# df_test['hour'] = df_test.hour.astype('category')\n",
    "# df_test['holiday'] = df_test.holiday.astype('category')\n",
    "# df_test['weekday'] = df_test.weekday.astype('category')\n",
    "# df_test['workingday'] = df_test.workingday.astype('category')\n",
    "# df_test['weather'] = df_test.weather.astype('category')\n",
    "# =============================================================================\n",
    "\n",
    "df_test = df_test.drop(['windspeed','atemp'], axis=1)\n",
    "df_test = df_test[['temp', 'humidity', 'hour', 'month', 'workingday', 'holiday', 'season','weekday', 'year', 'weather']]\n",
    "df_test.shape\n",
    "\n",
    "y_pred = np.exp(voting.predict(df_test))\n",
    "True in (y_pred < 0)\n",
    "for i, y  in enumerate(y_pred):\n",
    "    if y_pred[i] < 0:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = range(y_pred.shape[0])\n",
    "submission['Predicted'] = y_pred\n",
    "submission.to_csv(\"new_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Υ.Γ. Παραπάνω έχουμε βάλει αρκετά κομμάτια κώδικα σε σχόλια.\n",
    "Για την εκτέλεση του κώδικα που είναι σε σχόλια:\n",
    "1. Επιλέγουμε τον κώδικα που θέλουμε να τρέξουμε\n",
    "2. Πατάμε ctrl+/ για να αφαιρεθεί από σχόλιο\n",
    "3. Τρέχουμε το αντίστοιχο πεδίο του Notebook.\n",
    "\n",
    "Για ευκολία παρέχουμε ένα ξεχωριστό αρχείο python που περιέχει όλο των κώδικα από τον οποίο προκύπτει το υποβληθέν αρχείο, χωρίς τα περιττά σχόλια που αφορούν μεθόδους που τελικά δεν ακολουθήσαμε, αλλά θέλαμε να αναφέρουμε."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
